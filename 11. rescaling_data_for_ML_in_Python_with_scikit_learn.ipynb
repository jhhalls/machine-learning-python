{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescaling Data for Machine Learning in Python with Scikit-Learn\n",
    "Your data must be prepared before you can build models. The data preparation process can involve three steps: data selection, data preprocessing and data transformation.\n",
    "\n",
    "In this post you will discover two simple data transformation methods you can apply to your data in Python using scikit-learn.\n",
    "\n",
    "## Data Rescaling\n",
    "Your preprocessed data may contain attributes with a mixtures of scales for various quantities such as dollars, kilograms and sales volume.\n",
    "\n",
    "Many machine learning methods expect or are more effective if the data attributes have the same scale. Two popular data scaling methods are normalization and standardization.\n",
    "\n",
    "## Data Normalization\n",
    "Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n",
    "\n",
    "It is useful to scale the input attributes for a model that relies on the magnitude of values, such as distance measures used in k-nearest neighbors and in the preparation of coefficients in regression.\n",
    "\n",
    "The example below demonstrate data normalization of the Iris flowers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data attributes for the Iris dataset.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "print(iris.data.shape)\n",
    "# separate the data from the target attributes\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# normalize the data attributes\n",
    "normalized_X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).\n",
    "\n",
    "It is useful to standardize attributes for a model that relies on the distribution of attributes such as Gaussian processes.\n",
    "\n",
    "The example below demonstrate data standardization of the Iris flowers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data attributes for the Iris dataset.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "# load the Iris dataset\n",
    "iris = load_iris()\n",
    "print(iris.data.shape)\n",
    "# separate the data and target attributes\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# standardize the data attributes\n",
    "standardized_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: Which Method To Use\n",
    "It is hard to know whether rescaling your data will improve the performance of your algorithms before you apply them. If often can, but not always.\n",
    "\n",
    "A good tip is to create rescaled copies of your dataset and race them against each other using your test harness and a handful of algorithms you want to spot check. This can quickly highlight the benefits (or lack there of) of rescaling your data with given models, and which rescaling method may be worthy of further investigation.\n",
    "\n",
    "## Summary\n",
    "Data rescaling is an important part of data preparation before applying machine learning algorithms.\n",
    "\n",
    "In this post you discovered where data rescaling fits into the process of applied machine learning and two methods: Normalization and Standardization that you can use to rescale your data in Python using the scikit-learn library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
